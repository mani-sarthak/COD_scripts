{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from psmpy import PsmPy\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file containing normalised covariates (with UID ie. primary key)\n",
    "df = pd.read_csv(\"*.csv\")\n",
    "norm = df.dropna()\n",
    "metadata = [] # depends on the data, remove everything except covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that index in the csv file has the name idx here (not id or index). Change that correspondingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psm = PsmPy(norm, treatment='Treatment', indx='idx', exclude = ['lon','lat'] + metadata)\n",
    "psm.logistic_ps(balance = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_scores = psm.predicted_data.copy()\n",
    "p_scores.set_index('idx',inplace=True)\n",
    "p_scores.sort_index(inplace=True)\n",
    "p_scores = p_scores[['propensity_score','propensity_logit']]\n",
    "p_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_psm = norm.join(p_scores)\n",
    "dataset_psm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_pairs(treated_df, non_treated_df):\n",
    "    treated_x = treated_df.values\n",
    "    non_treated_x = non_treated_df.values\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='brute').fit(non_treated_x)\n",
    "    distances, indices = nbrs.kneighbors(treated_x)\n",
    "    indices = indices.reshape(indices.shape[0])\n",
    "    matched = non_treated_df.iloc[indices]\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_psm.copy()\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matchings = pd.DataFrame()\n",
    "treated_df = df[(df['Treatment']==1)][['idx','propensity_logit']].set_index('idx')\n",
    "non_treated_df = df[(df['Treatment']==0)][['idx','propensity_logit']].set_index('idx')\n",
    "if len(treated_df)>0 and len(non_treated_df)>0:\n",
    "  matched_df = get_matching_pairs(treated_df, non_treated_df)\n",
    "  all_matching = pd.DataFrame({'idx': treated_df.index, 'matched_ID': matched_df.index})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change this accordingly as per the data you have. Try to write in the sae order as given in the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = all_matchings\n",
    "fields = ['idx'] + metadata + ['lat', 'lon', 'dist_closest_lin', 'dist_closest_river', 'dist_closest_road', 'dist_closest_upstream_forest', 'elevation',\n",
    " 'slope', 'flow_accumulation', 'proximity_water',  'drainage_density', \n",
    "#  'cropping_intensity_2016-2017',  \n",
    " 'HSG',\n",
    " 'CEC',\n",
    " 'PH',\n",
    " 'OC']\n",
    "print(len(fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_fields = fields + [a+'_matched' for a in fields]\n",
    "asset_cvts = pd.merge(matching, norm,  how='inner', left_on=['idx'], right_on = ['idx'])\n",
    "asset_cfs_cvts= pd.merge(asset_cvts, norm,  how='inner', left_on=['matched_ID'], right_on = ['idx'])\n",
    "asset_cfs_cvts = asset_cfs_cvts.drop(columns=['Treatment_x','Treatment_y','matched_ID'])\n",
    "asset_cfs_cvts.columns = all_fields\n",
    "matchings_df = asset_cfs_cvts\n",
    "matchings_df.to_csv(\"./matched.csv\", index=False)\n",
    "asset_cfs_cvts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## integraring the NDVI values after matching and DiD computation by Harshit"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
